{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from os.path import join as pjoin\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patheffects\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from sktime.classification.kernel_based import RocketClassifier, Arsenal\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xskillscore import Contingency\n",
    "\n",
    "from stndata import ONEMINUTESTNNAMES\n",
    "\n",
    "np.random.seed(1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the stations, and the manual storm classification data. That data is stored in a separate csv file, indexed by date and station number. We then split the storm data into a training set and a test set. Bear in mind this is still the subset of high quality stations. There's another 500-odd stations that we have processed to extract daily maximum wind gust data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASEDIR = r\"..\\data\"\n",
    "TRAINDIR = pjoin(BASEDIR, \"training\")\n",
    "\n",
    "stndf = pd.read_csv(pjoin(BASEDIR, 'hqstations.csv'), index_col=\"stnNum\")\n",
    "hqstndf = pd.read_csv(pjoin(BASEDIR, \"hqstations.csv\"), index_col=\"stnNum\")\n",
    "fullStationFile = pjoin(BASEDIR, \"StationDetails.geojson\")\n",
    "eventFile = pjoin(TRAINDIR, \"visual_storm_types.csv\")\n",
    "stormdf = pd.read_csv(eventFile, usecols=[1, 2, 3], parse_dates=['date'],\n",
    "                      dtype={'stnNum': int,\n",
    "                             'stormType': 'category'})\n",
    "\n",
    "#stormdf = pd.read_csv(eventFile, usecols=[2, 3, 4], parse_dates=['date'],\n",
    "#                dtype={'stnNum': float,\n",
    "#                       'stormType': 'category'},\n",
    "#                converters={'stnNum': lambda s: int(float(s.strip() or 0))})\n",
    "\n",
    "stormdf.set_index(['stnNum', 'date'], inplace=True)\n",
    "nevents = len(stormdf)\n",
    "\n",
    "# Take a random selection of 200 storms to test against:\n",
    "test_storms = stormdf.sample(200)\n",
    "train_storms = stormdf.drop(test_storms.index)\n",
    "ntrain = len(train_storms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn; sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(stnNum: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load event data for a given station. Missing values are interpolated\n",
    "    linearly - if values are missing at the start or end they are backfilled\n",
    "    from the nearest valid value.\n",
    "\n",
    "    This data has been extracted by `extractStationData.py`, and is stored in\n",
    "    pickle files, so there should be no issues around type conversions.\n",
    "\n",
    "    :param stnNum: BoM station number\n",
    "    :type stnNum: int\n",
    "    :return: DataFrame holding the data of all gust events for a station\n",
    "    :rtype: `pd.DataFrame`\n",
    "    \"\"\"\n",
    "    fname = pjoin(TRAINDIR, \"events\", f\"{stnNum:06d}.pkl\")\n",
    "    df = pd.read_pickle(fname)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['windgust'] = df['windgust'].interpolate(method='linear').bfill()\n",
    "    df['tempanom'] = df['tempanom'].interpolate(method='linear').bfill()\n",
    "    df['stnpanom'] = df['stnpanom'].interpolate(method='linear').bfill()\n",
    "    df['dpanom'] = df['dpanom'].interpolate(method='linear').bfill()\n",
    "    df['windspd'] = df['windspd'].interpolate(method='linear').bfill()\n",
    "    df['uanom'] = df['uanom'].interpolate(method='linear').bfill()\n",
    "    df['vanom'] = df['vanom'].interpolate(method='linear').bfill()\n",
    "    vars = ['windgust', 'tempanom', 'stnpanom',\n",
    "            'dpanom', 'windspd', 'uanom', 'vanom']\n",
    "\n",
    "    #for idx, tmpdf in df.groupby('date'):\n",
    "    #    scaler = StandardScaler()\n",
    "    #    scalevals = scaler.fit_transform(tmpdf[vars].values)\n",
    "    #    df.loc[df['date'] == idx, vars] = scalevals\n",
    "\n",
    "    df['stnNum'] = stnNum\n",
    "    df.reset_index(inplace=True)\n",
    "    df.set_index(['stnNum', 'date'], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all the events into a single dataframe. We'll then pick out the events based on whether they are in the training set or the test set, using the index from the storm classification data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflist = []\n",
    "for stn in stndf.index:\n",
    "    df = loadData(stn)\n",
    "    dflist.append(df)\n",
    "\n",
    "alldf = pd.concat(dflist)\n",
    "alldf['idx'] = alldf.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the event data into training and test datasets. This is simple because we set the index of both the event data and the storm classification data to be the station number and date of the event. \n",
    "\n",
    "The event data needs to be reshaped into a 3-d array (for input into the classifier), where there are n events in the first dimension. The second dimension represents the time (-60 minutes to +60 minutes) and the third dimension represents the different variables. We can potentially vary the list of variables used, but we start with the wind gust and the anomalies of temperature, dewpoint and station pressure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventdf_train = alldf.loc[train_storms.index]\n",
    "eventdf_test = alldf.loc[test_storms.index]\n",
    "\n",
    "vars = ['windgust', 'tempanom', 'stnpanom', 'dpanom']\n",
    "scaler = StandardScaler()\n",
    "eventdf_train[vars] = scaler.fit_transform(eventdf_train[vars].values)\n",
    "eventdf_test[vars] = scaler.transform(eventdf_test[vars].values)\n",
    "\n",
    "nvars = len(vars)\n",
    "X = eventdf_train.reset_index().set_index(['idx', 'tdiff'])[vars]\n",
    "XX = np.moveaxis(X.values.reshape((ntrain, 121, nvars)), 1, -1)\n",
    "\n",
    "X_test = eventdf_test.reset_index().set_index(['idx', 'tdiff'])[vars]\n",
    "XX_test = np.moveaxis(X_test.values.reshape((200, 121, nvars)), 1, -1)\n",
    "\n",
    "fulltest = alldf.loc[stormdf.index].reset_index().set_index(['idx', 'tdiff'])[vars]\n",
    "fulltestarray = np.moveaxis(fulltest.values.reshape((len(stormdf), 121, nvars)), 1, -1)\n",
    "fully = np.array(list(stormdf.loc[fulltest.reset_index()['idx'].unique()]['stormType'].values))\n",
    "\n",
    "y = np.array(train_storms['stormType'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's where we train and run the classifier on the test event set. The classifier is fitted to the training data (`XX`), then we predict the class of the test data (`XX_test`). Results are compared to the visual classification of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the classifier: 0.695 (took 73.0 seconds)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prediction</th>\n",
       "      <th>Synoptic storm</th>\n",
       "      <th>Synoptic front</th>\n",
       "      <th>Storm-burst</th>\n",
       "      <th>Thunderstorm</th>\n",
       "      <th>Front up</th>\n",
       "      <th>Front down</th>\n",
       "      <th>Spike</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Synoptic storm</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synoptic front</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Storm-burst</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thunderstorm</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Front up</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Front down</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spike</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prediction      Synoptic storm  Synoptic front  Storm-burst  Thunderstorm  \\\n",
       "visual                                                                      \n",
       "Synoptic storm              62               1            3             1   \n",
       "Synoptic front               5              13            0             0   \n",
       "Storm-burst                 15               0            8             0   \n",
       "Thunderstorm                 1               0            4            23   \n",
       "Front up                     0               3            1             2   \n",
       "Front down                   0               0            1             9   \n",
       "Spike                        0               0            0             0   \n",
       "\n",
       "prediction      Front up  Front down  Spike  \n",
       "visual                                       \n",
       "Synoptic storm         0           0      0  \n",
       "Synoptic front         7           0      0  \n",
       "Storm-burst            0           0      0  \n",
       "Thunderstorm           4           2      0  \n",
       "Front up              14           0      0  \n",
       "Front down             1           6      0  \n",
       "Spike                  0           0     13  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rocket = RocketClassifier(num_kernels=10000)\n",
    "t0 = time.time()\n",
    "rocket.fit(XX, y)\n",
    "y_pred = rocket.predict(XX_test)\n",
    "t1 = time.time() - t0\n",
    "results = pd.DataFrame(data={'prediction':y_pred, 'visual':test_storms['stormType']})\n",
    "score = rocket.score(XX_test, test_storms['stormType'])\n",
    "print(f\"Accuracy of the classifier: {score} (took {t1:.1f} seconds)\")\n",
    "colorder = ['Synoptic storm', 'Synoptic front', 'Storm-burst',\n",
    "            'Thunderstorm', 'Front up', 'Front down',\n",
    "            'Spike', ]\n",
    "pd.crosstab(results['visual'], results['prediction']).reindex(colorder)[colorder]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We map the storm classes to an integer value for use in the `xskillscore` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapclass = {'Synoptic storm': 0,\n",
    "            'Synoptic front': 1,\n",
    "            'Storm-burst': 2,\n",
    "            'Thunderstorm': 3,\n",
    "            'Front up': 4,\n",
    "            'Front down': 5,\n",
    "            'Spike': 6}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we loop through the classification process using a range of number of kernels. Want to demonstrate the effect of increasing the number of kernels on the accuracy of the classification, versus the time to perform the classification. 50 iterations are performed, and then we calculate the mean and standard deviation of the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nkernels = [100, 200, 500, 1000, 2000, 5000, 10_000]\n",
    "stats = []\n",
    "for i in range(50):\n",
    "    for n in nkernels:\n",
    "        rocket = RocketClassifier(num_kernels=n)\n",
    "        t0 = time.time()\n",
    "        rocket.fit(XX, y)\n",
    "        y_pred = rocket.predict(XX_test)\n",
    "        t1 = time.time() - t0\n",
    "        results = pd.DataFrame(data={'prediction':y_pred, 'visual':test_storms['stormType']})\n",
    "        results['visint'] = results['visual'].map(mapclass)\n",
    "        results['predint'] = results['prediction'].map(mapclass)\n",
    "        xda = results.to_xarray()\n",
    "        ct = Contingency(xda.visint, xda.predint, observation_category_edges=np.arange(0, 7), forecast_category_edges=np.arange(0, 7), dim=['stnNum', 'date'])\n",
    "        acc = ct.accuracy()\n",
    "        hss = ct.heidke_score()\n",
    "        gs = ct.gerrity_score()\n",
    "        stats.append([i, n, t1, acc.data.item(), hss.data.item(), gs.data.item()])\n",
    "\n",
    "resdf = pd.DataFrame(stats, columns=('iteration', 'nkernels', 'time', 'accuracy', 'hss', 'gs'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower(x): return(x.mean() - x.std())\n",
    "def upper(x): return(x.mean() + x.std())\n",
    "\n",
    "resstats = resdf.groupby('nkernels').agg({'time': 'mean',\n",
    "                               'accuracy':['mean', 'std'],\n",
    "                               'hss':['mean', 'std'],\n",
    "                               'gs':['mean', 'std'],})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "resstats.to_excel(pjoin(TRAINDIR, \"classification_scoring.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will run the classification on all storms. Firstly, we run with 2000 random convolution kernels. This is an efficient and preliminary analysis of the performance of the classification algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocket = RocketClassifier(num_kernels=2000)\n",
    "rocket.fit(fulltestarray, fully)\n",
    "newclass = rocket.predict(fulltestarray)\n",
    "results = pd.DataFrame(data={'prediction':newclass, 'visual':fully})\n",
    "score = rocket.score(fulltestarray, fully)\n",
    "print(f\"Accuracy of the classifier: {score}\")\n",
    "colorder = ['Synoptic storm', 'Synoptic front', 'Storm-burst',\n",
    "            'Thunderstorm', 'Front up', 'Front down',\n",
    "            'Spike', 'Unclassified']\n",
    "pd.crosstab(results['visual'], results['prediction']).reindex(colorder)[colorder]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROCKET classifier shows a tendency to predict all storm types are Synoptic storms - there are 18 visually classified convective storms that are predicted as Synoptic storm\n",
    "\n",
    "Increasing the number of kernels substantially improves performance of the classification scheme. The score increases from 0.897 to 0.982. The number of incorrectly classified storms in the training dataset is reduced to just 18 out of 996 events. Of those, 12 are discussed in further detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocket = RocketClassifier(num_kernels=10000)\n",
    "rocket.fit(fulltestarray, fully)\n",
    "newclass = rocket.predict(fulltestarray)\n",
    "results = pd.DataFrame(data={'prediction':newclass, 'visual':fully})\n",
    "score = rocket.score(fulltestarray, fully)\n",
    "print(f\"Accuracy of the classifier: {score}\")\n",
    "colorder = ['Synoptic storm', 'Synoptic front', 'Storm-burst',\n",
    "            'Thunderstorm', 'Front up', 'Front down',\n",
    "            'Spike', 'Unclassified']\n",
    "pd.crosstab(results['visual'], results['prediction']).reindex(colorder)[colorder]\n",
    "pd.crosstab(results['visual'], results['prediction']).reindex(colorder)[colorder].to_excel(pjoin(BASEDIR, 'events', 'crosstab.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[(results.prediction=='Spike') & (results.visual.isin(['Synoptic storm', 'Synoptic front', 'Storm-burst']))].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stormdf.loc[fulltest.reset_index()['idx'].unique()].iloc[[966, 967, 968, 969, 970, 975, 977]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[(results.prediction=='Synoptic storm') & (results.visual.isin(['Spike']))].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stormdf.loc[fulltest.reset_index()['idx'].unique()].iloc[[442, 443, 444, 445, 447]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = rocket.predict_proba(fulltestarray)\n",
    "idx = [5, 4, 3, 6, 1, 0, 2, 7]\n",
    "#proba[:, idx]\n",
    "fig, ax = plt.subplots(figsize=(10,12))\n",
    "plt.imshow(proba[:, idx])\n",
    "ax.set_aspect(0.01)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the station data for all stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stndata import ONEMINUTESTNDTYPE, ONEMINUTESTNNAMES\n",
    "allstnfile = r\"X:\\georisk\\HaRIA_B_Wind\\data\\raw\\from_bom\\2022\\1-minute\\HD01D_StationDetails.txt\"\n",
    "\n",
    "allstndf = pd.read_csv(allstnfile, sep=',', index_col='stnNum',\n",
    "                            names=ONEMINUTESTNNAMES,\n",
    "                            keep_default_na=False,\n",
    "                            converters={\n",
    "                                'stnName': str.strip,\n",
    "                                'stnState': str.strip\n",
    "                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldatadflist = []\n",
    "for stn in allstndf.index:\n",
    "    try:\n",
    "        df = loadData(stn)\n",
    "    except FileNotFoundError:\n",
    "        pass  #print(f\"No data for station: {stn}\")\n",
    "    else:\n",
    "        alldatadflist.append(df)\n",
    "\n",
    "alldatadf = pd.concat(alldatadflist)\n",
    "alldatadf['idx'] = alldatadf.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allX = alldatadf.reset_index().set_index(['idx', 'tdiff'])[vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove any events with less than 2 hours of observations, and any remaining events with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "naidx = []\n",
    "for ind, tmpdf in allX.groupby(level='idx'):\n",
    "    #print(len(tmpdf))\n",
    "    if len(tmpdf) < 121:\n",
    "        naidx.append(ind)\n",
    "        print(ind, len(tmpdf))\n",
    "    if tmpdf.isna().sum().sum() > 0:\n",
    "        # Found NA values in the data (usually dew point)\n",
    "        naidx.append(ind)\n",
    "\n",
    "allXupdate = allX.drop(naidx, level='idx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the data for input to the ROCKET classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nstorms = int(len(allXupdate)/121)\n",
    "vars = ['windgust', 'tempanom', 'stnpanom', 'dpanom']\n",
    "nvars = len(vars)\n",
    "#allX = alldatadf.reset_index().set_index(['idx', 'tdiff'])[vars]\n",
    "allXX = np.moveaxis(allXupdate.values.reshape((nstorms, 121, nvars)), 1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stormclass = rocket.predict(allXX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stormclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputstormdf = pd.DataFrame(data={'stormType': stormclass}, index=allXupdate.index.get_level_values(0).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputstormdf.stormType.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputstormdf.stormType.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allXupdate['idx'] = allXupdate.index.get_level_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "synidx = outputstormdf[outputstormdf['stormType']==\"Synoptic storm\"].index\n",
    "syfidx = outputstormdf[outputstormdf['stormType']==\"Synoptic front\"].index\n",
    "sbidx = outputstormdf[outputstormdf['stormType']==\"Storm-burst\"].index\n",
    "\n",
    "tsidx = outputstormdf[outputstormdf['stormType']==\"Thunderstorm\"].index\n",
    "fuidx = outputstormdf[outputstormdf['stormType']==\"Front up\"].index\n",
    "fdidx = outputstormdf[outputstormdf['stormType']==\"Front down\"].index\n",
    "\n",
    "ucidx = outputstormdf[outputstormdf['stormType']==\"Unclassified\"].index\n",
    "spidx = outputstormdf[outputstormdf['stormType']==\"Spike\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synevents = allXupdate[allXupdate.index.get_level_values('idx').isin(synidx)]\n",
    "syfevents = allXupdate[allXupdate.index.get_level_values('idx').isin(syfidx)]\n",
    "sbevents = allXupdate[allXupdate.index.get_level_values('idx').isin(sbidx)]\n",
    "\n",
    "\n",
    "tsevents = allXupdate[allXupdate.index.get_level_values('idx').isin(tsidx.values)]\n",
    "fuevents = allXupdate[allXupdate.index.get_level_values('idx').isin(fuidx.values)]\n",
    "fdevents = allXupdate[allXupdate.index.get_level_values('idx').isin(fdidx.values)]\n",
    "\n",
    "ucevents = allXupdate[allXupdate.index.get_level_values('idx').isin(ucidx.values)]\n",
    "spevents = allXupdate[allXupdate.index.get_level_values('idx').isin(spidx.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meansyn = synevents.groupby('tdiff').mean().reset_index()\n",
    "meansyf = syfevents.groupby('tdiff').mean().reset_index()\n",
    "meansb = sbevents.groupby('tdiff').mean().reset_index()\n",
    "\n",
    "meants = tsevents.groupby('tdiff').mean().reset_index()\n",
    "meanfu = fuevents.groupby('tdiff').mean().reset_index()\n",
    "meanfd = fdevents.groupby('tdiff').mean().reset_index()\n",
    "\n",
    "meanuc = ucevents.groupby('tdiff').mean().reset_index()\n",
    "meansp = spevents.groupby('tdiff').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patheffects\n",
    "pe = patheffects.withStroke(foreground=\"white\", linewidth=5)\n",
    "\n",
    "def plotEvent(df):\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    #ax = fig.add_axes([0, 0, 1, 1])\n",
    "    #ax2 = ax.twinx()\n",
    "    axt = ax.twinx()\n",
    "    axp = ax.twinx()\n",
    "    ax.set_zorder(1)\n",
    "    ax.patch.set_visible(False)\n",
    "    lnt = axt.plot(df.tdiff, df.tempanom, label=r\"Temperature anomaly [$^o$C]\",\n",
    "             color='r', marker='^', markerfacecolor=\"None\", lw=2, path_effects=[pe], zorder=1,\n",
    "             markevery=5)\n",
    "    lnd = axt.plot(df.tdiff, df.dpanom, color='orangered', marker='.', markerfacecolor=\"None\",\n",
    "             lw=1, path_effects=[pe], zorder=1, markevery=5, label=r\"Dew point anomaly [$^o$C]\")\n",
    "\n",
    "    lnw = ax.plot(df.tdiff, df.windgust, label=\"Gust wind speed [km/h]\",\n",
    "            lw=3, path_effects=[pe], markerfacecolor=\"None\",zorder=100)\n",
    "    lnp = axp.plot(df.tdiff, df.stnpanom, color='purple', lw=2, path_effects=[pe],\n",
    "             ls='--', label='Station pressure anomaly [hPa]')\n",
    "\n",
    "    #axt.spines['right'].set_position((\"axes\", 1.075))\n",
    "    axt.spines[['right']].set_color('r')\n",
    "    axt.yaxis.label.set_color('r')\n",
    "    axt.tick_params(axis='y', colors='r')\n",
    "    axt.set_ylabel(r\"Temperature/dewpoint anomaly [$^o$C]\")\n",
    "\n",
    "    ax.set_ylabel(\"Gust wind speed [km/h]\")\n",
    "\n",
    "    axp.spines[['right']].set_position(('axes', 1.075))\n",
    "    axp.spines[['right']].set_color('purple')\n",
    "    axp.yaxis.label.set_color('purple')\n",
    "    axp.tick_params(axis='y', colors='purple')\n",
    "    axp.set_ylabel(\"Pressure anomaly [hPa]\")\n",
    "\n",
    "    gmin, gmax = ax.get_ylim()\n",
    "    pmin, pmax = axp.get_ylim()\n",
    "    tmin, tmax = axt.get_ylim()\n",
    "    ax.set_ylim((0, max(gmax, 100)))\n",
    "    ax.set_xlabel(\"Time from gust peak(minutes)\")\n",
    "    axp.set_ylim((min(-2.0, pmin), max(pmax, 2.0)))\n",
    "    axt.set_ylim((min(-2.0, tmin), max(tmax, 2.0)))\n",
    "    #ax2.set_ylim((0, 360))\n",
    "    #ax2.set_yticks(np.arange(0, 361, 90))\n",
    "    #axr.set_ylim((0, 100))\n",
    "    #ax.set_title(meants.index[0])\n",
    "    ax.grid(True)\n",
    "    #ax2.grid(False)\n",
    "    axt.grid(False)\n",
    "    axp.grid(False)\n",
    "\n",
    "    lns = lnw + lnt + lnd + lnp\n",
    "    labs = [l.get_label() for l in lns]\n",
    "\n",
    "    ax.legend(lns, labs, )\n",
    "    #axr.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotEvent(meants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotEvent(meanfu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotEvent(meanfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotEvent(meansyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotEvent(meansyf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotEvent(meansb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotEvent(meansp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotEvent(meanuc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('sktime')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6eacf74b18b37d56e760b681462e94465875e1f6e8e41eaf2cd6ab24d5297ceb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
